### Data Scientist sp√©cialis√© en MLOps et Intelligence Artificielle ‚Äì Activit√© ind√©pendante

**Prestations de services en data science, automatisation, mod√®les de machine learning et solutions d‚Äôintelligence artificielle.**

En tant qu‚Äôexpert en data science, je vous accompagne dans la transformation de vos donn√©es en leviers strat√©giques. Gr√¢ce √† l‚Äôextraction d‚Äôinsights pertinents et au d√©veloppement de mod√®les intelligents, j‚Äôapporte une vision √©clair√©e pour optimiser vos prises de d√©cision. Mon agilit√©, ma curiosit√© analytique et mon approche proactive constituent des atouts majeurs pour toute entreprise souhaitant affiner sa strat√©gie et am√©liorer l‚Äôefficacit√© de ses processus d√©cisionnels. 
Je privil√©gie des solutions analytiques performantes, durables et adapt√©es aux enjeux sp√©cifiques de votre activit√©.
#### Formations
- Machine Learning Enginner
- Master Data Science
- Certificat Data Science

#### Comp√©tences cl√©s.

**Machine Learning :**
- Machine Learning & Deep Learning
- Scikit-Learn, XGBoost, Random Forest
- NLP (transformers, embeddings), clustering
- Feature engineering & optimisation des mod√®les
- Optimisation : GridSearch, Optuna, Random Search
- √âvaluation : AUC, F1-Score, confusion matrice
- Interpr√©tabilit√© : SHAP, LIME
- √âvaluation robuste : cross-validation, tests statistiques
  
**IA & NLP :**
- Syst√®mes RAG (Retrieval-Augmented Generation)
- LLMs (GPT, Mistral, Zephyr, LLaMA 3)
- Fine-tuning mod√®les open-source (HuggingFace)
- Tokenisation, embeddings, FAISS, vector databases
- Prompt engineering & prompt optimisation
  
**MLOps & D√©ploiement :** 
- Docker, Docker Compose
- GitHub Actions (CI/CD)
- MLflow (tracking, versioning, registry)
- D√©ploiement Streamlit Cloud, HuggingFace Spaces, Render, Azure ML
- Monitoring des mod√®les (drift, performance, latence)
- Packaging, pipelines, automatisation
  
**Backend & Dev :**
- Python (avanc√©), FastAPI (API ML), Streamlit (UI ML)
- Pipelines ETL/ELT
- Gestion des environnements (conda, venv), Makefile
- Tests unitaires (pytest), logging structur√©
  
**Data Engineering :**
- SQL, PostgreSQL
- Data modeling, star schema
- Extraction et transformation de donn√©es
- Gestion de donn√©es semi-structur√©es (JSON, XML, parquet)

**Cloud & DevOps :**
- Azure ML / Azure Storage
- HuggingFace Spaces
- Streamlit Cloud
- Git & GitHub avanc√©
- Automatisation CI/CD
  
**Outils :**
- Python ¬∑ Pandas ¬∑ NumPy ¬∑ Scikit-learn ¬∑ FAISS ¬∑ LangChain ¬∑ HuggingFace ¬∑ Transformers
- Docker ¬∑ Git ¬∑ GitHub Actions ¬∑ MLflow ¬∑ Streamlit ¬∑ FastAPI ¬∑ SQL


#### Exp√©riences
üîπData Scientist | Cov√©a | [Dates]
üìç Paris, France.
- Optimis√© la tarification MRH en d√©veloppant un mod√®le dynamique (Python, SQL), r√©duisant l‚Äô√©cart-type des primes de 15 %.
- Analys√© 10M+ sinistres auto (PySpark, SQL), identifiant des facteurs de risque et r√©duisant les co√ªts d‚Äôindemnisation de 10 %.
- Renforc√© la lutte antifraude en impl√©mentant un mod√®le IA (Random Forest, Gradient Boosting), am√©liorant la d√©tection de 30 %.
- Industrialis√© le scoring de fraude via AWS Sagemaker, r√©duisant le temps de d√©tection de 40 %.
- D√©ploy√© des dashboards interactifs (Power BI, Tableau), optimisant l‚Äôinterpr√©tation des insights m√©tiers.

üîπData Scientist | Ufirst Advisory | [Dates]
üìç Paris, France.
- Optimis√© le traitement des donn√©es (+50M lignes) avec SQL, Pandas, PySpark, r√©duisant le temps de pr√©paration de 30 %.
- Explor√© et visualis√© les donn√©es (Matplotlib, Seaborn, Plotly), am√©liorant l‚Äôanalyse exploratoire et la prise de d√©cision.
- Am√©lior√© les pr√©visions de vente de 15 % via des mod√®les pr√©dictifs avanc√©s (XGBoost, LightGBM, Random Forest).
- Automatis√© le d√©ploiement des mod√®les (Docker, AWS Lambda), r√©duisant le time-to-production de 40 %.
- Restitu√© des insights clairs en Power BI, Tableau, Dash, facilitant la prise de d√©cision m√©tier.

üîπ Charg√© d'√©tudes statistiques | Altocis-P.S.| [Dates]
üìç Paris, France.
- Con√ßu des dashboards dynamiques (Excel, Power BI), clarifiant les insights pour la direction.
- Automatis√© le suivi des KPI, r√©duisant le temps d‚Äôanalyse de 30 %.
- G√©r√© 500+ documents comptables (SQL, Excel VBA), assurant une saisie de donn√©es pr√©cise.
- Fournit des analyses strat√©giques, influen√ßant les d√©cisions op√©rationnelles.
- Optimis√© la planification des agents, r√©duisant les conflits d‚Äôhoraires de 25 %.

#### Projets: 
### Projet 1 : Assistant RH Intelligent bas√© sur l‚ÄôIA G√©n√©rative (RAG + LLM + FAISS).
[Code source GitHub | D√©mo interactive](https://github.com/DataEngineer87/Chatbot-Rh-Rag?tab=readme-ov-file)
#### D√©mo :
<img src="images/photo/CHATBOOT.png" width="400">

**Objectif du projet**

Les entreprises, disposent des informations RH (t√©l√©travail, cong√©s, formation, primes...) sont souvent dispers√© dans des fichiers PDF longs et difficiles √† consulter.
Ce projet a pour objectif La mise en palce d'un assistant IA capable de :
- Comprendre une question RH en langage naturel
- Rechercher automatiquement la r√©ponse dans les documents PDF internes
- G√©n√©rer une r√©ponse claire et contextualis√©e.

**Technos**
- OpenAI, HuggingFace, LangChain, FAISS 
- Streamlit, GitHub Actions

**Fonctionnalit√©s**
- Extraction PDF RH
- Embeddings MiniLM + index FAISS
- RAG complet : recherche + g√©n√©ration
- Streamlit UI
- CI/CD GitHub Actions
- D√©ploiement Streamlit Cloud
  
**Impact**
- Acc√©l√®re l‚Äôacc√®s √† l‚Äôinformation RH
- R√©duction du temps RH / collaborateurs
- D√©monstration compl√®te d‚Äôun projet IA bout-en-bout
  
**Solution technique**

D√©veloppement d‚Äôun syst√®me **RAG** complet (PDF ‚Üí embeddings ‚Üí LLM)
- 0% hallucinations gr√¢ce √† un filtrage strict bas√© sur la similarit√© vectorielle
- Gestion multi-PDF pour un r√©f√©rentiel RH complet
- Architecture modulaire : API ind√©pendante de l‚ÄôUI
- Compatible 100% Open-Source (version HuggingFace)
- Compatible OpenAI pour une qualit√© premium 

**Comp√©tences d√©montr√©es**
- IA G√©n√©rative (RAG complet)
- NLP avanc√©
- Vector Search (FAISS)
- HuggingFace embeddings + LLM
- Streamlit front-end
- Gestion des secrets & configuration streamlit cloud
- Structuration professionnelle de projet IA

#### Projet 2 : Pr√©diction du Statut de Compte Client
[Code source GitHub | D√©mo interactive](https://github.com/DataEngineer87/Statut-Compte-Clients)
#### D√©mo :
<img src="images/photo/COMPTE_CLIENT_page-0001.jpg" width="400">

**Objectif du projet**
- D√©veloppement et industrialisation d'un syst√®me complet capable de pr√©dire automatiquement le statut d‚Äôun compte client (actif, dormant, √† risque‚Ä¶) 
  gr√¢ce √† un pipeline Machine Learning enti√®rement orchestr√© en MLOps.
  Le projet combine FastAPI, Docker, GitHub Actions, MLflow, Streamlit Cloud et SHAP pour un cycle de vie ML industrialis√©, tra√ßable et explicable.

**Ce projet vise √† :**
- R√©duire la charge op√©rationnelle de tri et contr√¥le manuel des comptes.
- Fiabiliser la prise de d√©cision via un mod√®le explicable.
- Automatiser l‚Äôentra√Ænement, l‚Äô√©valuation, le d√©ploiement et le monitoring du mod√®le.
  
**R√©sultats obtenus**
- Pipeline MLOps complet : entra√Ænement ‚Üí tests ‚Üí tracking ‚Üí d√©ploiement ‚Üí monitoring.
- API FastAPI conteneuris√©e (Docker) mise en production via GitHub Actions (CI/CD).
- Dashboard Streamlit Cloud pour r√©aliser des pr√©dictions en ligne.
- Tests unitaires (pytest) automatis√©s √† chaque push GitHub.
- Analyse SHAP pour expliquer les pr√©dictions en d√©tail.
- Versioning complet des mod√®les et m√©triques via MLflow.
- Monitoring continu : suivi des d√©rives de donn√©es et de performance.

**Stack technique**
- Python, FastAPI, Docker, GitHub Actions, MLflow,
- Streamlit, SHAP, scikit-learn, pandas, pytest

#### Caract√©ristiques techniques du pipeline
**Pr√©paration & Feature Engineering**
- Nettoyage, encodage, imputation.
- S√©lection d‚Äôattributs bas√©e sur importance.
- Standardisation dynamique pour √©viter les fuites.

**Entra√Ænement du mod√®le**
- Mod√®le choisi : Random Forest.
- Hyperparameter tuning automatis√©.
- Logging automatique dans MLflow Tracking : m√©triques (accuracy, f1-score, recall‚Ä¶), param√®tres, artefacts, mod√®le pickl√©

**CI/CD avec GitHub Actions**
- D√©clenchement automatique √† chaque push : Installation de l‚Äôenvironnement, Ex√©cution des tests unitaires (pytest), Construction Docker,
  D√©ploiement automatique de l‚ÄôAPI

**API FastAPI**

Endpoint principal : POST /predict -> renvoie :
- classe pr√©dite
- explication SHAP

**Interface Streamlit**

Accessible en ligne :
- upload direct de CSV
- pr√©diction individuelle 

**Explicabilit√© (Explainable AI)**

Analyse produite par SHAP :
- Importance globale des variables
- Importance locale pour chaque pr√©diction
  
Cela rend le mod√®le audit-compatible pour les m√©tiers (finance, risque, conformit√©).

**Impact business**
- Automatisation d‚Äôun processus m√©tier critique
- Suppression des erreurs humaines
- Explicabilit√© conforme aux attentes l√©gales
- Acc√©l√©ration du temps de d√©cision
- Solution d√©ploy√©e en environnement cloud

### Projet 3 : Segmentation Client Avanc√©e - RFM, K-Means & DBSCAN
[Code source GitHub | D√©mo interactive](https://github.com/DataEngineer87/Customer-Segmentation-Ecommerce-rfm-kmeans-dbscan)

#### D√©mo :
<img src="images/photo/RFM.png" width="400">

**Technologies :** 

- Python
- Pandas
- Scikit-learn
- Plotly
- Streamlit
**M√©thodes :**
- RFM
- Means
- DBSCAN
**Domaine :**
- Customer Analytics
- Marketing Intelligence

**Objectif**

Concevoir une segmentation client exploitable business pour prioriser les actions marketing, CRM et fid√©lisation dans un contexte e-commerce r√©el.

**Approche**
- RFM : mesure de la valeur client (VIP, √† risque, nouveaux, perdus)
- K-Means : segmentation comportementale non supervis√©e
- DBSCAN : d√©tection des clients atypiques / anomalies
- Fusion des r√©sultats dans une vue strat√©gique unique

**R√©sultats**
- Typologie finale : VIP ¬∑ √Ä Risque ¬∑ Standard ¬∑ Atypiques
- Interpr√©tation automatique des segments
- Dashboard interactif Streamlit
- Export de clients actionnables
- 
**Projet orient√© d√©cision business, pr√™t pour un d√©ploiement cloud.**

