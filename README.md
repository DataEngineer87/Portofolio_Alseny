## Data Scientist confirm√© orient√© MLOps & GenAI
En tant qu‚Äôexpert en data science, je vous accompagne dans la transformation de vos donn√©es en leviers strat√©giques. Gr√¢ce √† l‚Äôextraction d‚Äôinsights pertinents et au d√©veloppement de mod√®les intelligents, j‚Äôapporte une vision √©clair√©e pour optimiser vos prises de d√©cision. Mon agilit√©, ma curiosit√© analytique et mon approche proactive constituent des atouts majeurs pour toute entreprise souhaitant affiner sa strat√©gie et am√©liorer l‚Äôefficacit√© de ses processus d√©cisionnels. 
Je privil√©gie des solutions analytiques performantes, durables et adapt√©es aux enjeux sp√©cifiques de votre activit√©.
## Formations
- Machine Learning Enginner
- Master Data Science
- Certificat Data Science

## Comp√©tences cl√©s.

**Machine Learning :**
- Machine Learning & Deep Learning
- Scikit-Learn, XGBoost, Random Forest
- NLP (transformers, embeddings), clustering
- Feature engineering & optimisation des mod√®les
- Optimisation : GridSearch, Optuna, Random Search
- √âvaluation : AUC, F1-Score, confusion matrice
- Interpr√©tabilit√© : SHAP, LIME
- √âvaluation robuste : cross-validation, tests statistiques
  
**IA & NLP :**
- Syst√®mes RAG (Retrieval-Augmented Generation)
- LLMs (GPT, Mistral, Zephyr, LLaMA 3)
- Fine-tuning mod√®les open-source (HuggingFace)
- Tokenisation, embeddings, FAISS, vector databases
- Prompt engineering & prompt optimisation
  
**MLOps & D√©ploiement :** 
- Docker, Docker Compose
- GitHub Actions (CI/CD)
- MLflow (tracking, versioning, registry)
- D√©ploiement Streamlit Cloud, HuggingFace Spaces, Render, Azure ML
- Monitoring des mod√®les (drift, performance, latence)
- Packaging, pipelines, automatisation
  
**Backend & Dev :**
- Python (avanc√©), FastAPI (API ML), Streamlit (UI ML)
- Pipelines ETL/ELT
- Gestion des environnements (conda, venv), Makefile
- Tests unitaires (pytest), logging structur√©
  
**Data Engineering :**
- SQL, PostgreSQL
- Data modeling, star schema
- Extraction et transformation de donn√©es
- Gestion de donn√©es semi-structur√©es (JSON, XML, parquet)

**Cloud & DevOps :**
- Azure ML / Azure Storage
- HuggingFace Spaces
- Streamlit Cloud
- Git & GitHub avanc√©
- Automatisation CI/CD
  
**Outils :**
- Python ¬∑ Pandas ¬∑ NumPy ¬∑ Scikit-learn ¬∑ FAISS ¬∑ LangChain ¬∑ HuggingFace ¬∑ Transformers
- Docker ¬∑ Git ¬∑ GitHub Actions ¬∑ MLflow ¬∑ Streamlit ¬∑ FastAPI ¬∑ SQL


## Exp√©riences
üîπData Scientist | Cov√©a | [Dates]
üìç Paris, France.
- Optimis√© la tarification MRH en d√©veloppant un mod√®le dynamique (Python, SQL), r√©duisant l‚Äô√©cart-type des primes de 15 %.
- Analys√© 10M+ sinistres auto (PySpark, SQL), identifiant des facteurs de risque et r√©duisant les co√ªts d‚Äôindemnisation de 10 %.
- Renforc√© la lutte antifraude en impl√©mentant un mod√®le IA (Random Forest, Gradient Boosting), am√©liorant la d√©tection de 30 %.
- Industrialis√© le scoring de fraude via AWS Sagemaker, r√©duisant le temps de d√©tection de 40 %.
- D√©ploy√© des dashboards interactifs (Power BI, Tableau), optimisant l‚Äôinterpr√©tation des insights m√©tiers.

üîπData Scientist | Ufirst Advisory | [Dates]
üìç Paris, France.
- Optimis√© le traitement des donn√©es (+50M lignes) avec SQL, Pandas, PySpark, r√©duisant le temps de pr√©paration de 30 %.
- Explor√© et visualis√© les donn√©es (Matplotlib, Seaborn, Plotly), am√©liorant l‚Äôanalyse exploratoire et la prise de d√©cision.
- Am√©lior√© les pr√©visions de vente de 15 % via des mod√®les pr√©dictifs avanc√©s (XGBoost, LightGBM, Random Forest).
- Automatis√© le d√©ploiement des mod√®les (Docker, AWS Lambda), r√©duisant le time-to-production de 40 %.
- Restitu√© des insights clairs en Power BI, Tableau, Dash, facilitant la prise de d√©cision m√©tier.

üîπ Charg√© d'√©tudes statistiques | Altocis-P.S.| [Dates]
üìç Paris, France.
- Con√ßu des dashboards dynamiques (Excel, Power BI), clarifiant les insights pour la direction.
- Automatis√© le suivi des KPI, r√©duisant le temps d‚Äôanalyse de 30 %.
- G√©r√© 500+ documents comptables (SQL, Excel VBA), assurant une saisie de donn√©es pr√©cise.
- Fournit des analyses strat√©giques, influen√ßant les d√©cisions op√©rationnelles.
- Optimis√© la planification des agents, r√©duisant les conflits d‚Äôhoraires de 25 %.

## Projets: 
### Projet 1 : Assistant RH Intelligent bas√© sur l‚ÄôIA G√©n√©rative (RAG + LLM + FAISS).
[Code source GitHub | D√©mo interactive](https://github.com/DataEngineer87/Chatbot-Rh-Rag?tab=readme-ov-file)
#### D√©mo :
<img src="images/photo/CHATBOOT.png" width="400">

**Objectif du projet**

Les entreprises, disposent des informations RH (t√©l√©travail, cong√©s, formation, primes...) sont souvent dispers√© dans des fichiers PDF longs et difficiles √† consulter.
Ce projet a pour objectif La mise en palce d'un assistant IA capable de :
- Comprendre une question RH en langage naturel
- Rechercher automatiquement la r√©ponse dans les documents PDF internes
- G√©n√©rer une r√©ponse claire et contextualis√©e.

**Technos**
- OpenAI, HuggingFace, LangChain, FAISS 
- Streamlit, GitHub Actions

**Fonctionnalit√©s**
- Extraction PDF RH
- Embeddings MiniLM + index FAISS
- RAG complet : recherche + g√©n√©ration
- Streamlit UI
- CI/CD GitHub Actions
- D√©ploiement Streamlit Cloud
  
**Impact**
- Acc√©l√®re l‚Äôacc√®s √† l‚Äôinformation RH
- R√©duction du temps RH / collaborateurs
- D√©monstration compl√®te d‚Äôun projet IA bout-en-bout
  
**Solution technique**

D√©veloppement d‚Äôun syst√®me **RAG** complet (PDF ‚Üí embeddings ‚Üí LLM)
- 0% hallucinations gr√¢ce √† un filtrage strict bas√© sur la similarit√© vectorielle
- Gestion multi-PDF pour un r√©f√©rentiel RH complet
- Architecture modulaire : API ind√©pendante de l‚ÄôUI
- Compatible 100% Open-Source (version HuggingFace)
- Compatible OpenAI pour une qualit√© premium 

**Comp√©tences d√©montr√©es**
- IA G√©n√©rative (RAG complet)
- NLP avanc√©
- Vector Search (FAISS)
- HuggingFace embeddings + LLM
- Streamlit front-end
- Gestion des secrets & configuration streamlit cloud
- Structuration professionnelle de projet IA

### Projet 2 : Pr√©diction du Statut de Compte Client
[Code source GitHub | D√©mo interactive](https://github.com/DataEngineer87/Statut-Compte-Clients)
#### D√©mo :
<img src="images/photo/COMPTE_CLIENT_page-0001.jpg" width="400">

**Objectif du projet**
- D√©veloppement et industrialisation d'un syst√®me complet capable de pr√©dire automatiquement le statut d‚Äôun compte client (actif, dormant, √† risque‚Ä¶) 
  gr√¢ce √† un pipeline Machine Learning enti√®rement orchestr√© en MLOps.
  Le projet combine FastAPI, Docker, GitHub Actions, MLflow, Streamlit Cloud et SHAP pour un cycle de vie ML industrialis√©, tra√ßable et explicable.

**Ce projet vise √† :**
- R√©duire la charge op√©rationnelle de tri et contr√¥le manuel des comptes.
- Fiabiliser la prise de d√©cision via un mod√®le explicable.
- Automatiser l‚Äôentra√Ænement, l‚Äô√©valuation, le d√©ploiement et le monitoring du mod√®le.
  
**R√©sultats obtenus**
- Pipeline MLOps complet : entra√Ænement ‚Üí tests ‚Üí tracking ‚Üí d√©ploiement ‚Üí monitoring.
- API FastAPI conteneuris√©e (Docker) mise en production via GitHub Actions (CI/CD).
- Dashboard Streamlit Cloud pour r√©aliser des pr√©dictions en ligne.
- Tests unitaires (pytest) automatis√©s √† chaque push GitHub.
- Analyse SHAP pour expliquer les pr√©dictions en d√©tail.
- Versioning complet des mod√®les et m√©triques via MLflow.
- Monitoring continu : suivi des d√©rives de donn√©es et de performance.

**Stack technique**
- Python, FastAPI, Docker, GitHub Actions, MLflow,
- Streamlit, SHAP, scikit-learn, pandas, pytest

#### Caract√©ristiques techniques du pipeline
**Pr√©paration & Feature Engineering**
- Nettoyage, encodage, imputation.
- S√©lection d‚Äôattributs bas√©e sur importance.
- Standardisation dynamique pour √©viter les fuites.

**Entra√Ænement du mod√®le**
- Mod√®le choisi : Random Forest.
- Hyperparameter tuning automatis√©.
- Logging automatique dans MLflow Tracking : m√©triques (accuracy, f1-score, recall‚Ä¶), param√®tres, artefacts, mod√®le pickl√©

**CI/CD avec GitHub Actions**
- D√©clenchement automatique √† chaque push : Installation de l‚Äôenvironnement, Ex√©cution des tests unitaires (pytest), Construction Docker,
  D√©ploiement automatique de l‚ÄôAPI

**API FastAPI**

Endpoint principal : POST /predict -> renvoie :
- classe pr√©dite
- explication SHAP

**Interface Streamlit**

Accessible en ligne :
- upload direct de CSV
- pr√©diction individuelle 

**Explicabilit√© (Explainable AI)**

Analyse produite par SHAP :
- Importance globale des variables
- Importance locale pour chaque pr√©diction
  
Cela rend le mod√®le audit-compatible pour les m√©tiers (finance, risque, conformit√©).

**Impact business**
- Automatisation d‚Äôun processus m√©tier critique
- Suppression des erreurs humaines
- Explicabilit√© conforme aux attentes l√©gales
- Acc√©l√©ration du temps de d√©cision
- Solution d√©ploy√©e en environnement cloud
- 
### Projet 3 : Segmentation Client Avanc√©e - RFM, K-Means & DBSCAN
[Code source GitHub | D√©mo interactive](https://customer-segmentation-ecommerce-rfm-kmeans-dbscan-ogdvmz6rtytd.streamlit.app/)

#### D√©mo :
<img src="images/photo/RFM.png" width="400">

#### CONTEXTE BUSINESS
**Probl√©matique**
Une entreprise e-commerce dispose de milliers de clients, mais :
- elle cherche √† savoir qui prioriser
- ne distingue pas les clients rentables
- ignore les clients atypiques ou √† risque
  
**Objectif**

Construire une segmentation client exploitable m√©tier pour :
- augmenter la valeur client
- r√©duire le churn
- guider les actions marketing & CRM
  
**DONN√âES & PR√âPARATION**

- Dataset r√©el Olist (Br√©sil)
- +100 000 transactions
- Niveau transactionnel ‚Üí client
  
**Nettoyage & pr√©paration**
- Filtrage des commandes livr√©es
- Suppression des doublons
- Conversion des dates
- Agr√©gation client (RFM)
  
**R√©sultat obtenu :** une base client propre et actionnable
### M√©thodes
#### M√©thode 1 - SEGMENTATION RFM
- Recency : r√©cence du dernier achat
- Frequency : nombre de commandes
- Monetary : montant total d√©pens√©
- Scoring 1‚Äì5 (quantiles + fallback)

**Segments obtenus**
- Champions
- Clients fid√®les
- Clients prometteurs
- Nouveaux clients
- √Ä surveiller
- √Ä r√©activer
- √Ä risque
- Perdus

**Impact business**
- Priorisation marketing
- Lecture simple pour √©quipes m√©tier
- Vision valeur client claire
#### M√©thode 2 - K-MEANS (SEGMENTATION COMPORTEMENTALE)
**Objectif**
Identifier des groupes de clients similaires, sans r√®gles m√©tiers.

**Variables utilis√©es**

- Recency
- Frequency
- Monetary
- Score moyen d‚Äôavis
- Paiements moyens

**D√©marches**
- Normalisation MinMax
- S√©lection de K via Silhouette Score
- Visualisations interactives (Plotly)
**R√©sultats obtenus**
- Meilleur K identifi√© automatiquement
- Clusters interpr√©t√©s par profil moyen
- G√©n√©ration automatique d‚Äôinterpr√©tations business
#### M√©thode 3 - DBSCAN (CLIENTS ATYPIQUES)
**Objectif**

D√©tecter les clients hors normes :
- comportements extr√™mes
- anomalies
- profils √† fort risque ou opportunit√©

**D√©marches**

- Standardisation robuste
- DBSCAN (eps + min_samples)
- K-distance plot automatique

**R√©sultat obtenu**
- Label -1 = clients atypiques
- Export vers fichier actionnable

#### VUE STRAT√âGIQUE FINALE (CEO / CRM VIEW)
Fusion **RFM + K-Means + DBSCAN**

**Typologie clients**

- VIP
- √Ä Risque
- Standard
- Atypiques
- Vue orient√©e d√©cision & priorisation, pas algorithme.
  
**DASHBOARD STREAMLIT**

Fonctionnalit√©s :

- Upload CSV
- Filtres dynamiques
- Visualisations interactives
- Interpr√©tation automatique
- Export clients actionnables
- d√©ploiement cloud Streamlit
## Monitoring ‚Äì Stabilit√© de la Segmentation
[Code source GitHub | D√©mo interactive](https://customer-segmentation-ecommerce-rfm-kmeans-dbscan-kje2pukjdu2t.streamlit.app/)
#### D√©mo :
<img src="images/photo/ARI.png" width="400">

**Objectif du monitoring**

Dans un contexte de segmentation **non supervis√©e (K-Means / DBSCAN)**, il n‚Äôexiste pas de "v√©rit√© terrain".

Le monitoring vise donc √† :
- D√©tecter les d√©rives comportementales clients
- Garantir la stabilit√© des clusters dans le temps
- D√©cider quand retrainer le mod√®le
  
**Principe retenu : Adjusted Rand Index (ARI)**
  
L‚Äô**Adjusted Rand Index (ARI)** mesure la similarit√© entre deux partitions de clusters :

- ARI = 1 ‚Üí clusters parfaitement stables
- ARI ‚âà 0 ‚Üí structure al√©atoire
- ARI < 0 ‚Üí d√©rive majeure
Ce **monitoring temporel (Rolling Window)**
- Fen√™tre historique (window_days) : P√©riode de r√©f√©rence servant de baseline.
- Pas temporel (step_days) : Fr√©quence de recalcul de la segmentation

**Exemple**
- Fen√™tre = 365 jours
- Pas = 7 jours

Le mod√®le est compar√© chaque semaine √† la segmentation de r√©f√©rence (ann√©e N-1).

**Politique d‚Äôalertes**
**ARI  	              Statut     	              Action                      D√©cision**
ARI ‚â• 0.30	         Stable	                    Aucune action               Retrain trimestriel
0.20 ‚â§ ARI < 0.30	   D√©rive d√©tect√©e	          Surveillance accrue         Retrain mensuel
ARI < 0.20	         D√©rive critique	          Retrain imm√©diat            Retrain imm√©diat

Cette logique est impl√©ment√©e directement dans le pipeline de monitoring.

**Visualisation & Dashboard**

Le monitoring est expos√© via un dashboard Streamlit interactif :

- Courbe ARI dans le temps
- Seuils m√©tiers visuels
- Alertes en temps r√©el
- Param√©trage dynamique (k, fen√™tre, pas)

**Valeur business**

- Anticipation de la perte de performance
- Meilleure priorisation clients (VIP / √Ä risque / Atypiques)
- D√©cisions data-driven pour le CRM et le marketing
